{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7549a17b-849f-45eb-9a1b-b85d450447e0",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "Mix of libraries for data preprocessing, visualization, and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "882d5aa7-5837-4c0f-9b47-79bd7b9969d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 21:33:18.617841: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "import imagesize\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5c062a-9374-41a1-ac72-932d2b9b4702",
   "metadata": {},
   "source": [
    "## Exploration\n",
    "\n",
    "Here, we will be creating a dataframe with all our image paths (as strings), bloodcell type, and image dimension information. We will take a look at if our data is balanced or not with the bloodcell type counts and the image dimension counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad63fb38-d092-4954-b8c2-d7488d87c56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['basophil',\n",
       " 'neutrophil',\n",
       " 'ig',\n",
       " 'monocyte',\n",
       " 'eosinophil',\n",
       " 'erythroblast',\n",
       " 'lymphocyte',\n",
       " 'platelet']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset folder has 8 different folders, which represent 8 different bloodcells we will be classifying\n",
    "# Open up folder names and remove folder names that are not bloodcell types\n",
    "\n",
    "# Original kaggle dataset has images stored in each of the 8 folders, so we made a folder that contained all the images\n",
    "# so that it is easier to convert the images to numpy arrays later on\n",
    "\n",
    "bloodcells = os.listdir(\"bloodcells_dataset\")\n",
    "bloodcells = [x for x in bloodcells if x not in ['.DS_Store', 'All_Images']]\n",
    "\n",
    "bloodcells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63160923-03db-4c6d-9690-64e2ff43f73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_df(folder_names):\n",
    "\n",
    "    '''\n",
    "    Outputs a dataframe for image paths (as strings), bloodcell type, and image dimension information.\n",
    "\n",
    "    Args:\n",
    "        1) folder_names (list): list of bloodcell type folders\n",
    "\n",
    "    Returns:\n",
    "        Dataframe with all image paths, bloodcell types, and image dimensions\n",
    "    '''\n",
    "\n",
    "    # initialize empty list to store dataframes that contain image strings and bloodcell type\n",
    "    dfs = []\n",
    "\n",
    "    # loop through bloodcell types and store image paths and bloodcell categories\n",
    "    for i in range(len(folder_names)):\n",
    "\n",
    "        # jpg string paths\n",
    "        images = os.listdir('bloodcells_dataset/' + folder_names[i]) \n",
    "\n",
    "        # dataframe holding specific bloodcell type info (string path and type name)\n",
    "        df = pd.DataFrame(data = {'images': images, 'type': folder_names[i]})\n",
    "\n",
    "        # append dataframe to list\n",
    "        dfs.append(df)\n",
    "\n",
    "    # combine all dataframes\n",
    "    all_data = pd.concat(dfs)\n",
    "\n",
    "    # Remove image paths that may have been accidentally copied or contain .DS_Store\n",
    "    all_data = all_data[all_data['images'].str.contains('.DS_Store') == False]\n",
    "    all_data = all_data[all_data['images'].str.contains('copy') == False]\n",
    "\n",
    "    # Convert bloodcell types to numbers for our model\n",
    "    le = LabelEncoder()\n",
    "    all_data['type_category'] = all_data['type'] # keep a copy of bloodcell types by name\n",
    "    all_data['type'] = le.fit_transform(all_data['type'])\n",
    "\n",
    "    # Store dimensions of image incase we find different dimensions \n",
    "    dimensions = pd.Series([imagesize.get('bloodcells_dataset/All_Images/' + x) for x in all_data['images']])\n",
    "    widths, heights = map(list, zip(*dimensions))\n",
    "    all_data['width'] = widths\n",
    "    all_data['height'] = heights\n",
    "\n",
    "    # Reset index \n",
    "    all_data = all_data.reset_index(drop = True)\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27d61789-b0a5-4b10-9339-866eb38e8a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>type</th>\n",
       "      <th>type_category</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BA_689200.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>basophil</td>\n",
       "      <td>360</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BA_883452.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>basophil</td>\n",
       "      <td>360</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BA_382161.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>basophil</td>\n",
       "      <td>366</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BA_175579.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>basophil</td>\n",
       "      <td>360</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BA_775722.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>basophil</td>\n",
       "      <td>360</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17087</th>\n",
       "      <td>PLATELET_495918.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>platelet</td>\n",
       "      <td>360</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17088</th>\n",
       "      <td>PLATELET_897238.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>platelet</td>\n",
       "      <td>360</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17089</th>\n",
       "      <td>PLATELET_750430.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>platelet</td>\n",
       "      <td>360</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17090</th>\n",
       "      <td>PLATELET_810431.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>platelet</td>\n",
       "      <td>360</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17091</th>\n",
       "      <td>PLATELET_499850.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>platelet</td>\n",
       "      <td>360</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17092 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    images  type type_category  width  height\n",
       "0            BA_689200.jpg     0      basophil    360     363\n",
       "1            BA_883452.jpg     0      basophil    360     363\n",
       "2            BA_382161.jpg     0      basophil    366     369\n",
       "3            BA_175579.jpg     0      basophil    360     363\n",
       "4            BA_775722.jpg     0      basophil    360     363\n",
       "...                    ...   ...           ...    ...     ...\n",
       "17087  PLATELET_495918.jpg     7      platelet    360     363\n",
       "17088  PLATELET_897238.jpg     7      platelet    360     363\n",
       "17089  PLATELET_750430.jpg     7      platelet    360     363\n",
       "17090  PLATELET_810431.jpg     7      platelet    360     363\n",
       "17091  PLATELET_499850.jpg     7      platelet    360     363\n",
       "\n",
       "[17092 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = image_df(bloodcells)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "970a3e57-80ad-4791-8320-39692f45fab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visuals for count of height/width and count of each blood cell type\n",
    "# Maybe use function to plot\n",
    "\n",
    "# df[['height', 'width']].value_counts().reset_index(name = 'count') \n",
    "# df[['type_category']].value_counts().reset_index(name = 'count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e46f4355-e4ed-423d-89d8-f4e31d2e5b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling:\n",
    "\n",
    "    def __init__(self, data, sampling_method):\n",
    "\n",
    "        self.data = data\n",
    "        \n",
    "        self.sampling_method = sampling_method\n",
    "\n",
    "    def sample_data(self, sampling_percent = 0.8):\n",
    "\n",
    "        df = self.data.copy()\n",
    "\n",
    "        category_counts = df[['type']].value_counts().reset_index(name = 'count')\n",
    "\n",
    "        train_dfs = []\n",
    "\n",
    "        if self.sampling_method == 'weighted':\n",
    "\n",
    "            for i in range(len(category_counts)):\n",
    "\n",
    "                type = category_counts['type'][i]\n",
    "            \n",
    "                if category_counts['count'][i] >= 2000:\n",
    "                    add_samples = df[df['type'] == type].sample(1500)\n",
    "                else: \n",
    "                    add_samples = df[df['type'] == type].sample(1000)\n",
    "\n",
    "                train_dfs.append(add_samples)\n",
    "            \n",
    "            train = pd.concat(train_dfs)\n",
    "\n",
    "            remaining_data = df[~df['images'].isin(train['images'])]\n",
    "    \n",
    "            validation = remaining_data.sample(int(len(remaining_data) / 2))\n",
    "        \n",
    "        elif self.sampling_method == 'proportional': \n",
    "\n",
    "            num_samples = int(sampling_percent * len(df))\n",
    "            \n",
    "            category_counts['prop'] = category_counts['count'] / len(df)\n",
    "            category_counts['train_samples'] = (category_counts['prop'] * num_samples).astype('int32')\n",
    "            category_counts['val_samples'] = (category_counts['train_samples'] * 0.2).astype('int32')\n",
    "            category_counts['train_samples'] = category_counts['train_samples'] - category_counts['val_samples']\n",
    "\n",
    "            val_dfs = []\n",
    "\n",
    "            for i in range(len(category_counts)):\n",
    "\n",
    "                type = category_counts['type'][i]\n",
    "            \n",
    "                samples = category_counts['train_samples'][i]\n",
    "            \n",
    "                add_samples = df[df['type'] == type].sample(samples)\n",
    "\n",
    "                train_dfs.append(add_samples)\n",
    "            \n",
    "            train = pd.concat(train_dfs)\n",
    "\n",
    "            remaining_data = df[~df['images'].isin(train['images'])]\n",
    "\n",
    "            for i in range(len(category_counts)):\n",
    "\n",
    "                type = category_counts['type'][i]\n",
    "            \n",
    "                samples = category_counts['val_samples'][i]\n",
    "            \n",
    "                add_samples = remaining_data[remaining_data['type'] == type].sample(samples)\n",
    "\n",
    "                val_dfs.append(add_samples)\n",
    "            \n",
    "            validation = pd.concat(val_dfs)\n",
    "\n",
    "        train = train.dropna(how = 'all')\n",
    "\n",
    "        float_cols = train.select_dtypes(np.number)\n",
    "\n",
    "        train[float_cols.columns] = float_cols.astype('int32')\n",
    "\n",
    "        test = remaining_data[~remaining_data['images'].isin(validation['images'])]\n",
    "\n",
    "        return train, validation, test\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12f24ebb-9579-4255-9ec1-0988dc5aeed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_sampling = Sampling(df, 'weighted')\n",
    "proportional_sampling = Sampling(df, 'proportional')\n",
    "\n",
    "weighted_train, weighted_val, weighted_test = weighted_sampling.sample_data()\n",
    "prop_train, prop_val, prop_test = proportional_sampling.sample_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68225d0e-9948-457f-ba14-dee6f4920d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convert_Images:\n",
    "\n",
    "    def __init__(self, data):\n",
    "\n",
    "        self.data = data\n",
    "\n",
    "        self.file_names = (self.data)['images'].apply(lambda x: 'bloodcells_dataset/All_Images/' + x)\n",
    "\n",
    "        self.labels = self.data['type']\n",
    "\n",
    "    def load_image(self, file_name, resize):\n",
    "        \n",
    "        raw = tf.io.read_file(file_name)\n",
    "        \n",
    "        tensor = tf.io.decode_image(raw, expand_animations = False)\n",
    "        \n",
    "        tensor = tf.image.resize(tensor, size = [resize, resize])\n",
    "        \n",
    "        tensor = tf.cast(tensor, tf.float32) / 255.0\n",
    "        \n",
    "        return tensor\n",
    "\n",
    "    def image_arrays_and_labels(self, resize = 32):\n",
    "\n",
    "      dataset = tf.data.Dataset.from_tensor_slices(self.file_names)\n",
    "        \n",
    "      dataset = dataset.map(lambda file_name: self.load_image(file_name, resize))\n",
    "        \n",
    "      images = np.array(list(dataset))\n",
    "        \n",
    "      return images, self.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fbedfb7-47ac-4a9f-bb99-fabcd515af70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 20:56:16.159803: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "weighted_train_image_df, weighted_val_image_df, weighted_test_image_df = Convert_Images(weighted_train), Convert_Images(weighted_val), Convert_Images(weighted_test) \n",
    "prop_train_image_df, prop_val_image_df, prop_test_image_df = Convert_Images(prop_train), Convert_Images(prop_val), Convert_Images(prop_test)\n",
    "\n",
    "\n",
    "\n",
    "resize_pixels = 32\n",
    "\n",
    "weighted_train_images, weighted_train_labels = weighted_train_image_df.image_arrays_and_labels(resize_pixels)\n",
    "weighted_val_images, weighted_val_labels = weighted_val_image_df.image_arrays_and_labels(resize_pixels)\n",
    "weighted_test_images, weighted_test_labels = weighted_test_image_df.image_arrays_and_labels(resize_pixels)\n",
    "prop_train_images, prop_train_labels = prop_train_image_df.image_arrays_and_labels(resize_pixels)\n",
    "prop_val_images, prop_val_labels = prop_val_image_df.image_arrays_and_labels(resize_pixels)\n",
    "prop_test_images, prop_test_labels = prop_test_image_df.image_arrays_and_labels(resize_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ea57916-e704-4f90-91af-205ba06661b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted_train_images: 10000\n",
      "weighted_val_images: 3546\n",
      "weighted_test_images: 3546\n",
      "prop_train_images: 10938\n",
      "prop_val_images: 2731\n",
      "prop_test_images: 3423\n"
     ]
    }
   ],
   "source": [
    "print(f'weighted_train_images: {len(weighted_train_images)}')\n",
    "print(f'weighted_val_images: {len(weighted_val_images)}')\n",
    "print(f'weighted_test_images: {len(weighted_test_images)}')\n",
    "print(f'prop_train_images: {len(prop_train_images)}')\n",
    "print(f'prop_val_images: {len(prop_val_images)}')\n",
    "print(f'prop_test_images: {len(prop_test_images)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8435b02e-1541-4ce4-b183-efca096a60df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data, train_labels, val_data, val_test, test_data, test_labels, optimizer = 'adam', epochs = 5, batch_size = 64):\n",
    "\n",
    "    model.compile(optimizer = optimizer,\n",
    "                  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True), \n",
    "                  metrics = ['accuracy'])\n",
    "\n",
    "    history = model.fit(train_data, \n",
    "                        train_labels, \n",
    "                        validation_data = (val_data, val_test),\n",
    "                        epochs = epochs, \n",
    "                        batch_size = batch_size)\n",
    "\n",
    "    predictions = (model.predict(test_data)).argmax(axis = 1)\n",
    "\n",
    "    test_accuracy = np.sum(predictions == test_labels) / len(test_labels)\n",
    "\n",
    "    return history, predictions, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ed2467d-ce27-4f82-b321-a8968fb0e00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st of 3 models\n",
    "# Simple model\n",
    "# One for weighted sampling and proportional sampling\n",
    "\n",
    "# Simple Model - Weighted Sampling\n",
    "sm_w = models.Sequential(\n",
    "    \n",
    "    [\n",
    "        layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (resize_pixels, resize_pixels, 3)),\n",
    "        \n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        layers.Conv2D(32, (3, 3), activation = 'relu'),\n",
    "        \n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "\n",
    "        # flatten into 1d array\n",
    "        layers.Flatten(),\n",
    "\n",
    "        # Neural network\n",
    "        layers.Dense(64, activation = 'relu'),\n",
    "\n",
    "        layers.Dropout(rate = 0.2),\n",
    "        \n",
    "        # 8 different categories\n",
    "        layers.Dense(8) \n",
    "    ]\n",
    "    \n",
    ")\n",
    "\n",
    "# Simple Model - Proportional Sampling\n",
    "sm_p = models.clone_model(sm_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d9e053d-f9db-408d-9f45-48b4403ce54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 1.4998 - accuracy: 0.4197 - val_loss: 0.8344 - val_accuracy: 0.7442\n",
      "Epoch 2/25\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.9156 - accuracy: 0.6532 - val_loss: 0.7235 - val_accuracy: 0.7250\n",
      "Epoch 3/25\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.7599 - accuracy: 0.7138 - val_loss: 0.6016 - val_accuracy: 0.7803\n",
      "Epoch 4/25\n",
      "157/157 [==============================] - 6s 36ms/step - loss: 0.6832 - accuracy: 0.7451 - val_loss: 0.5409 - val_accuracy: 0.8032\n",
      "Epoch 5/25\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.6214 - accuracy: 0.7663 - val_loss: 0.4607 - val_accuracy: 0.8339\n",
      "Epoch 6/25\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.5858 - accuracy: 0.7789 - val_loss: 0.4553 - val_accuracy: 0.8401\n",
      "Epoch 7/25\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.5463 - accuracy: 0.7896 - val_loss: 0.4306 - val_accuracy: 0.8376\n",
      "Epoch 8/25\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.5168 - accuracy: 0.8049 - val_loss: 0.3821 - val_accuracy: 0.8500\n",
      "Epoch 9/25\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.4836 - accuracy: 0.8190 - val_loss: 0.5694 - val_accuracy: 0.7910\n",
      "Epoch 10/25\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.4537 - accuracy: 0.8284 - val_loss: 0.3880 - val_accuracy: 0.8590\n",
      "Epoch 11/25\n",
      "157/157 [==============================] - 6s 37ms/step - loss: 0.4475 - accuracy: 0.8346 - val_loss: 0.3798 - val_accuracy: 0.8598\n",
      "Epoch 12/25\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.4143 - accuracy: 0.8487 - val_loss: 0.3940 - val_accuracy: 0.8522\n",
      "Epoch 13/25\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.3883 - accuracy: 0.8576 - val_loss: 0.3146 - val_accuracy: 0.8945\n",
      "Epoch 14/25\n",
      "157/157 [==============================] - 6s 40ms/step - loss: 0.3789 - accuracy: 0.8611 - val_loss: 0.2954 - val_accuracy: 0.8911\n",
      "Epoch 15/25\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.3446 - accuracy: 0.8758 - val_loss: 0.2631 - val_accuracy: 0.9112\n",
      "Epoch 16/25\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.3334 - accuracy: 0.8779 - val_loss: 0.2844 - val_accuracy: 0.8957\n",
      "Epoch 17/25\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 0.3120 - accuracy: 0.8886 - val_loss: 0.4503 - val_accuracy: 0.8421\n",
      "Epoch 18/25\n",
      "157/157 [==============================] - 7s 42ms/step - loss: 0.3204 - accuracy: 0.8848 - val_loss: 0.2799 - val_accuracy: 0.9007\n",
      "Epoch 19/25\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.2920 - accuracy: 0.8971 - val_loss: 0.2604 - val_accuracy: 0.9103\n",
      "Epoch 20/25\n",
      "157/157 [==============================] - 6s 39ms/step - loss: 0.2761 - accuracy: 0.8999 - val_loss: 0.2568 - val_accuracy: 0.9092\n",
      "Epoch 21/25\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.2585 - accuracy: 0.9091 - val_loss: 0.2527 - val_accuracy: 0.9117\n",
      "Epoch 22/25\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.2539 - accuracy: 0.9112 - val_loss: 0.2493 - val_accuracy: 0.9143\n",
      "Epoch 23/25\n",
      "157/157 [==============================] - 6s 41ms/step - loss: 0.2479 - accuracy: 0.9100 - val_loss: 0.2874 - val_accuracy: 0.8883\n",
      "Epoch 24/25\n",
      "157/157 [==============================] - 7s 43ms/step - loss: 0.2390 - accuracy: 0.9150 - val_loss: 0.2810 - val_accuracy: 0.8999\n",
      "Epoch 25/25\n",
      "157/157 [==============================] - 7s 44ms/step - loss: 0.2396 - accuracy: 0.9144 - val_loss: 0.2873 - val_accuracy: 0.9036\n",
      "111/111 [==============================] - 1s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "sm_w_history, sm_w_predictions, sm_w_test_accuracy = train_model(sm_w,\n",
    "                                                                 weighted_train_images,\n",
    "                                                                 weighted_train_labels,\n",
    "                                                                 weighted_val_images,\n",
    "                                                                 weighted_val_labels,\n",
    "                                                                 weighted_test_images,\n",
    "                                                                 weighted_test_labels,\n",
    "                                                                 epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19b30932-2847-44c0-8672-b33fb28e5ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "171/171 [==============================] - 7s 40ms/step - loss: 1.3934 - accuracy: 0.4882 - val_loss: 0.9134 - val_accuracy: 0.6822\n",
      "Epoch 2/25\n",
      "160/171 [===========================>..] - ETA: 0s - loss: 0.8668 - accuracy: 0.6823"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sm_p_history, sm_p_predictions, sm_p_test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msm_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                                                 \u001b[49m\u001b[43mprop_train_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                                                 \u001b[49m\u001b[43mprop_train_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                                                 \u001b[49m\u001b[43mprop_val_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                                                 \u001b[49m\u001b[43mprop_val_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                                                 \u001b[49m\u001b[43mprop_test_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                                                 \u001b[49m\u001b[43mprop_test_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                                                 \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_data, train_labels, val_data, val_test, test_data, test_labels, optimizer, epochs, batch_size)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(model, train_data, train_labels, val_data, val_test, test_data, test_labels, optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m):\n\u001b[1;32m      3\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(optimizer \u001b[38;5;241m=\u001b[39m optimizer,\n\u001b[1;32m      4\u001b[0m                   loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy(from_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m), \n\u001b[1;32m      5\u001b[0m                   metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 7\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m (model\u001b[38;5;241m.\u001b[39mpredict(test_data))\u001b[38;5;241m.\u001b[39margmax(axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     15\u001b[0m     test_accuracy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(predictions \u001b[38;5;241m==\u001b[39m test_labels) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(test_labels)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sm_p_history, sm_p_predictions, sm_p_test_accuracy = train_model(sm_p,\n",
    "                                                                 prop_train_images,\n",
    "                                                                 prop_train_labels,\n",
    "                                                                 prop_val_images,\n",
    "                                                                 prop_val_labels,\n",
    "                                                                 prop_test_images,\n",
    "                                                                 prop_test_labels, \n",
    "                                                                 epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc3e39c-3ac7-4be4-8499-1f019e3fb762",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_w_test_accuracy, sm_p_test_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
