{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa344e92-cd93-41b1-b490-5ae2db2de245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "import imagesize\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad63fb38-d092-4954-b8c2-d7488d87c56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['basophil', 'neutrophil', '.DS_Store', 'ig', 'monocyte', 'All_Images', 'eosinophil', 'erythroblast', 'lymphocyte', 'platelet']\n"
     ]
    }
   ],
   "source": [
    "bloodcells = os.listdir(\"bloodcells_dataset\")\n",
    "\n",
    "print(bloodcells)\n",
    "\n",
    "bloodcells.remove('.DS_Store')\n",
    "bloodcells.remove('All_Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9498f58a-b13e-42fa-ba8e-3b262f5930a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>type</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BA_689200.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>363</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BA_883452.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>363</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BA_382161.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>369</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BA_175579.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>363</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BA_775722.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>363</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17087</th>\n",
       "      <td>PLATELET_495918.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>363</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17088</th>\n",
       "      <td>PLATELET_897238.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>363</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17089</th>\n",
       "      <td>PLATELET_750430.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>363</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17090</th>\n",
       "      <td>PLATELET_810431.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>363</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17091</th>\n",
       "      <td>PLATELET_499850.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>363</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17092 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    images  type  height  width\n",
       "0            BA_689200.jpg     0     363    360\n",
       "1            BA_883452.jpg     0     363    360\n",
       "2            BA_382161.jpg     0     369    366\n",
       "3            BA_175579.jpg     0     363    360\n",
       "4            BA_775722.jpg     0     363    360\n",
       "...                    ...   ...     ...    ...\n",
       "17087  PLATELET_495918.jpg     7     363    360\n",
       "17088  PLATELET_897238.jpg     7     363    360\n",
       "17089  PLATELET_750430.jpg     7     363    360\n",
       "17090  PLATELET_810431.jpg     7     363    360\n",
       "17091  PLATELET_499850.jpg     7     363    360\n",
       "\n",
       "[17092 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = os.listdir('bloodcells_dataset/' + bloodcells[0])\n",
    "df = pd.DataFrame(data = {'images': images, 'type': bloodcells[0], 'height': np.nan, 'width': np.nan})\n",
    "\n",
    "for i in range(1, len(bloodcells)):\n",
    "\n",
    "    images = os.listdir('bloodcells_dataset/' + bloodcells[i]) # jpg string paths\n",
    "    \n",
    "    images_df = pd.DataFrame(data = {'images': images, 'type': bloodcells[i], 'height': np.nan, 'width': np.nan})\n",
    "    \n",
    "    df = pd.concat([df, images_df])\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "df['width'] = df['images'].apply(lambda x: imagesize.get('bloodcells_dataset/All_Images/' + x)[0])\n",
    "df['height'] = df['images'].apply(lambda x: imagesize.get('bloodcells_dataset/All_Images/' + x)[1])\n",
    "df['type'] = le.fit_transform(df['type'])\n",
    "df.index = range(len(df.index))\n",
    "\n",
    "df = df[df['images'].str.contains('copy') == False]\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "970a3e57-80ad-4791-8320-39692f45fab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>363</td>\n",
       "      <td>360</td>\n",
       "      <td>16639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>369</td>\n",
       "      <td>366</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>360</td>\n",
       "      <td>360</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>361</td>\n",
       "      <td>360</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>360</td>\n",
       "      <td>359</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>360</td>\n",
       "      <td>361</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>360</td>\n",
       "      <td>362</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   height  width  count\n",
       "0     363    360  16639\n",
       "1     369    366    250\n",
       "2     360    360    198\n",
       "3     361    360      2\n",
       "4     360    359      1\n",
       "5     360    361      1\n",
       "6     360    362      1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['height', 'width']].value_counts().reset_index(name = 'count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72bbbb06-80ba-4874-89a8-8e31c98e2afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>3329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>2348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>1214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  count\n",
       "0     6   3329\n",
       "1     1   3117\n",
       "2     3   2895\n",
       "3     7   2348\n",
       "4     2   1551\n",
       "5     5   1420\n",
       "6     0   1218\n",
       "7     4   1214"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_counts = df[['type']].value_counts().reset_index(name = 'count')\n",
    "\n",
    "total_num_images = category_counts['count'].sum()\n",
    "\n",
    "category_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68a5f73b-2293-485b-84fb-8d2f2467ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted Sampling\n",
    "\n",
    "# high representation - types 1, 3, 6, 7 (sample 1500)\n",
    "# low representation - types 0, 2, 4, 5 (sample 1000)\n",
    "\n",
    "df_weighted_sampling_train = df[df['type'] == 6].sample(1500)\n",
    "\n",
    "for i in range(1, len(category_counts)):\n",
    "\n",
    "    type = category_counts['type'][i]\n",
    "\n",
    "    if category_counts['count'][i] >= 2000:\n",
    "        add_samples = df[df['type'] == type].sample(1500)\n",
    "    else: \n",
    "        add_samples = df[df['type'] == type].sample(1000)\n",
    "\n",
    "    df_weighted_sampling_train = pd.concat([df_weighted_sampling_train, add_samples])\n",
    "\n",
    "df_weighted_sampling_test = df[~df['images'].isin(df_weighted_sampling_train['images'])]\n",
    "\n",
    "resize_pixels = 64\n",
    "\n",
    "# Train\n",
    "weighted_sampling_train_images = np.array(\n",
    "    [np.array(Image.open('bloodcells_dataset/All_Images/' + image).resize((resize_pixels, resize_pixels))) for image in df_weighted_sampling_train['images']]\n",
    ")\n",
    "\n",
    "weighted_sampling_train_images = tf.convert_to_tensor(weighted_sampling_train_images / 255.0)\n",
    "\n",
    "weighted_sampling_train_labels = tf.convert_to_tensor(df_weighted_sampling_train['type'])\n",
    "\n",
    "# Test\n",
    "weighted_sampling_test_images = np.array(\n",
    "    [np.array(Image.open('bloodcells_dataset/All_Images/' + image).resize((resize_pixels, resize_pixels))) for image in df_weighted_sampling_test['images']]\n",
    ")\n",
    "\n",
    "weighted_sampling_test_images = tf.convert_to_tensor(weighted_sampling_test_images / 255.0)\n",
    "\n",
    "weighted_sampling_test_labels = tf.convert_to_tensor(df_weighted_sampling_test['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b74bf0e4-5b7d-4fbb-9b83-68477c65889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportional Sampling\n",
    "\n",
    "num_samples = int(0.8 * total_num_images)\n",
    "\n",
    "category_counts['prop'] = category_counts['count'] / total_num_images\n",
    "category_counts['prop_samples'] = category_counts['prop'] * num_samples\n",
    "category_counts['prop_samples'] = category_counts['prop_samples'].astype('int32')\n",
    "\n",
    "df_prop_sampling_train = df[df['type'] == 6].sample(2663)\n",
    "\n",
    "for i in range(1, len(category_counts)):\n",
    "\n",
    "    type = category_counts['type'][i]\n",
    "\n",
    "    samples = category_counts['prop_samples'][i]\n",
    "\n",
    "    add_samples = df[df['type'] == type].sample(samples)\n",
    "\n",
    "    df_prop_sampling_train = pd.concat([df_prop_sampling_train, add_samples])\n",
    "\n",
    "df_prop_sampling_test = df[~df['images'].isin(df_prop_sampling_train['images'])]\n",
    "\n",
    "resize_pixels = 64\n",
    "\n",
    "# # Train\n",
    "weighted_prop_train_images = np.array(\n",
    "     [np.array(Image.open('bloodcells_dataset/All_Images/' + image).resize((resize_pixels, resize_pixels))) for image in df_prop_sampling_train['images']]\n",
    " )\n",
    "\n",
    "weighted_prop_train_images = tf.convert_to_tensor(weighted_prop_train_images / 255.0)\n",
    "\n",
    "weighted_prop_train_labels = tf.convert_to_tensor(df_prop_sampling_train['type'])\n",
    "\n",
    "# Test\n",
    "weighted_prop_test_images = np.array(\n",
    "  [np.array(Image.open('bloodcells_dataset/All_Images/' + image).resize((resize_pixels, resize_pixels))) for image in df_prop_sampling_test['images']]\n",
    ")\n",
    "\n",
    "weighted_prop_test_images = tf.convert_to_tensor(weighted_prop_test_images / 255.0)\n",
    "\n",
    "weighted_prop_test_labels = tf.convert_to_tensor(df_prop_sampling_test['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2c400e9-3c3d-4b12-982d-1d837b06fcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening an image\n",
    "# test_img = Image.open('bloodcells_dataset/All_Images/' + df['images'][14000])\n",
    "\n",
    "# Resize\n",
    "# test_img.resize((320, 320))\n",
    "\n",
    "# Crop\n",
    "# test_img.crop((20, 20, 340, 340))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ed2467d-ce27-4f82-b321-a8968fb0e00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "157/157 [==============================] - 19s 113ms/step - loss: 1.1435 - accuracy: 0.5724\n",
      "Epoch 2/5\n",
      "157/157 [==============================] - 21s 134ms/step - loss: 0.5507 - accuracy: 0.7981\n",
      "Epoch 3/5\n",
      "157/157 [==============================] - 19s 122ms/step - loss: 0.4302 - accuracy: 0.8437\n",
      "Epoch 4/5\n",
      "157/157 [==============================] - 18s 113ms/step - loss: 0.3489 - accuracy: 0.8731\n",
      "Epoch 5/5\n",
      "157/157 [==============================] - 18s 113ms/step - loss: 0.2979 - accuracy: 0.8941\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = models.Sequential(\n",
    "    \n",
    "    [\n",
    "        # 32 kernels, 3 by 3 kernel\n",
    "        # input is 300 by 300 pixels with 3 color channels\n",
    "        layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (resize_pixels, resize_pixels, 3)),\n",
    "        \n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        layers.Conv2D(32, (3, 3), activation = 'relu'),\n",
    "        \n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "\n",
    "        # flatten into 1d array\n",
    "        layers.Flatten(),\n",
    "\n",
    "        # Neural network\n",
    "        layers.Dense(64, activation = 'relu'),\n",
    "\n",
    "        # 10 different categories\n",
    "        layers.Dense(8) \n",
    "    ]\n",
    "    \n",
    ")\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True), # using from_logits = True b/c no softmax layer\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(weighted_sampling_train_images, \n",
    "                    weighted_sampling_train_labels, \n",
    "                    epochs = 5, \n",
    "                    batch_size = 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1a7c91-add5-49dd-9c45-4bb0edcd6994",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(weighted_sampling_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "224ada18-276f-43a1-bf1f-cb8d1c84c952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "157/157 [==============================] - 19s 115ms/step - loss: 1.2639 - accuracy: 0.5129\n",
      "Epoch 2/5\n",
      "157/157 [==============================] - 19s 122ms/step - loss: 0.8252 - accuracy: 0.7026\n",
      "Epoch 3/5\n",
      "157/157 [==============================] - 19s 120ms/step - loss: 0.6283 - accuracy: 0.7768\n",
      "Epoch 4/5\n",
      "157/157 [==============================] - 19s 122ms/step - loss: 0.4814 - accuracy: 0.8338\n",
      "Epoch 5/5\n",
      "157/157 [==============================] - 20s 126ms/step - loss: 0.4104 - accuracy: 0.8519\n"
     ]
    }
   ],
   "source": [
    "# codes for average pooling:\n",
    "# ##tf.keras.layers.AveragePooling2D(\n",
    "#     pool_size=(2, 2),\n",
    "#     strides=None,\n",
    "#     padding='same',\n",
    "#     data_format=None\n",
    "# )\n",
    "\n",
    "random.seed(102849)\n",
    "\n",
    "avgPool_model = models.Sequential(\n",
    "    [\n",
    "        layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (resize_pixels, resize_pixels, 3)),\n",
    "        \n",
    "        layers.AveragePooling2D((2, 2), strides=None, padding='valid', data_format=None),\n",
    "        \n",
    "        layers.Conv2D(32, (3, 3), activation = 'relu'),\n",
    "        \n",
    "        layers.AveragePooling2D((2, 2), strides=None, padding='valid', data_format=None),\n",
    "        \n",
    "        layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "\n",
    "        # flatten into 1d array\n",
    "        layers.Flatten(),\n",
    "\n",
    "        # Neural network\n",
    "        layers.Dense(64, activation = 'relu'),\n",
    "\n",
    "        # 10 different categories\n",
    "        layers.Dense(8) \n",
    "    ]\n",
    ")\n",
    "\n",
    "avgPool_model.compile(optimizer = 'adam',\n",
    "              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True), # using from_logits = True b/c no softmax layer\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "history = avgPool_model.fit(weighted_sampling_train_images, \n",
    "                    weighted_sampling_train_labels, \n",
    "                    epochs = 5, \n",
    "                    batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4450a50-02ba-4035-920f-9dcb245b931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10439)\n",
    "\n",
    "from keras.layers import Input,Conv2D\n",
    "from tensorflow.keras.layers import DepthwiseConv2D\n",
    "\n",
    "def matlab_style_gauss2D(shape=(3,3),sigma=0.5):\n",
    "    \"\"\"\n",
    "    2D gaussian mask - should give the same result as MATLAB's\n",
    "    fspecial('gaussian',[shape],[sigma])\n",
    "    \"\"\"\n",
    "    m,n = [(ss-1.)/2. for ss in shape]\n",
    "    y,x = np.ogrid[-m:m+1,-n:n+1]\n",
    "    h = np.exp( -(x*x + y*y) / (2.*sigma*sigma) )\n",
    "    h[ h < np.finfo(h.dtype).eps*h.max() ] = 0\n",
    "    sumh = h.sum()\n",
    "    if sumh != 0:\n",
    "        h /= sumh\n",
    "    return h\n",
    "\n",
    "kernel_size = 3\n",
    "kernel_weights = matlab_style_gauss2D()\n",
    "\n",
    "kernel_weights = np.expand_dims(kernel_weights, axis=-1)\n",
    "kernel_weights = np.repeat(kernel_weights, 3, axis=-1)\n",
    "kernel_weights = np.expand_dims(kernel_weights, axis=-1)\n",
    "\n",
    "gaussian_model = models.Sequential(\n",
    "    [\n",
    "        layers.DepthwiseConv2D((kernel_size,kernel_size), use_bias=False, padding='same', data_format=None),\n",
    "        \n",
    "        layers.AveragePooling2D((2, 2), strides=None, padding='same', data_format=None),\n",
    "        \n",
    "        layers.DepthwiseConv2D((kernel_size,kernel_size), use_bias=False, padding='same', data_format=None),\n",
    "        \n",
    "        layers.AveragePooling2D((2, 2), strides=None, padding='same', data_format=None),\n",
    "        \n",
    "        layers.DepthwiseConv2D((kernel_size,kernel_size), use_bias=False, padding='same', data_format=None),\n",
    "\n",
    "        # flatten into 1d array\n",
    "        layers.Flatten(),\n",
    "\n",
    "        # Neural network\n",
    "        layers.Dense(64, activation = 'relu'),\n",
    "\n",
    "        # 10 different categories\n",
    "        layers.Dense(8) \n",
    "    ]\n",
    ")\n",
    "\n",
    "gaussian_model.compile(optimizer = 'adam',\n",
    "              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True), # using from_logits = True b/c no softmax layer\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9e1fb5b-89e7-4228-98de-8e74fc54f095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "214/214 [==============================] - 10s 43ms/step - loss: 1.4141 - accuracy: 0.4662\n",
      "Epoch 2/5\n",
      "214/214 [==============================] - 12s 56ms/step - loss: 0.9750 - accuracy: 0.6440\n",
      "Epoch 3/5\n",
      "214/214 [==============================] - 16s 75ms/step - loss: 0.8444 - accuracy: 0.6974\n",
      "Epoch 4/5\n",
      "214/214 [==============================] - 18s 86ms/step - loss: 0.7732 - accuracy: 0.7316\n",
      "Epoch 5/5\n",
      "214/214 [==============================] - 22s 104ms/step - loss: 0.7238 - accuracy: 0.7487\n"
     ]
    }
   ],
   "source": [
    "# Average pooling model using proportional sampling method\n",
    "history = gaussian_model.fit(weighted_prop_train_images, \n",
    "                    weighted_prop_train_labels, \n",
    "                    epochs = 5, \n",
    "                    batch_size = 64)\n",
    "\n",
    "# # Average pooling model using weighted sampling method\n",
    "# history = avgPool_model.fit(weighted_sampling_train_images, \n",
    "#                     weighted_sampling_train_labels, \n",
    "#                     epochs = 5, \n",
    "#                     batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2623d5db-e818-439d-887a-67de5f6c1f55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
